"""
AI Integration Pipeline
Shows how to integrate fraud detection into ETL workflow
3 different integration points
"""
import logging
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from etl.transform import transform_data
from ml.ai_fraud_detector import BlockchainFraudDetector

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class AIEnrichedETL:
    """ETL Pipeline with AI fraud detection integrated"""
    
    def __init__(self, detector=None):
        self.detector = detector or BlockchainFraudDetector()
        self.detector.load_or_create_model()
    
    # ============================================================
    # INTEGRATION POINT 1: AFTER TRANSFORM (Easiest & Recommended)
    # ============================================================
    
    def enrich_with_fraud_scores(self, raw_transactions):
        """
        BEST APPROACH FOR REAL-TIME
        
        Flow:
        Extract (raw) â†’ Transform (clean) â†’ AI Enrich (fraud scores) â†’ Output
        
        Advantages:
        âœ… Clean data ready for ML
        âœ… No database needed
        âœ… Works with real-time processor
        âœ… Lightweight & fast
        """
        logger.info("ğŸ§  AI ENRICHMENT (Point 1: After Transform)")
        
        # Step 1: Transform data
        df_clean = transform_data(raw_transactions)
        
        # Step 2: Add fraud scores
        df_enriched = self.detector.predict(df_clean, threshold=0.5)
        
        # Step 3: Add anomaly scores (unsupervised)
        df_enriched = self.detector.anomaly_detection(df_clean, contamination=0.1)
        
        return df_enriched
    
    # ============================================================
    # INTEGRATION POINT 2: BEFORE LOAD (Database Alternative)
    # ============================================================
    
    def filter_before_load(self, raw_transactions, db_insert_normal_only=True):
        """
        BEST APPROACH FOR STORAGE WITH FILTERING
        
        Flow:
        Extract â†’ Transform â†’ AI Filter â†’ Load Only Safe Transactions
        
        Advantages:
        âœ… Keep database clean (only verified data)
        âœ… Save storage (skip suspicious)
        âœ… Faster queries (smaller database)
        âœ… Good for production
        
        Args:
            db_insert_normal_only: Only load normal transactions to DB
        """
        logger.info("ğŸ§  AI FILTERING (Point 2: Before Load)")
        
        df_clean = transform_data(raw_transactions)
        df_enriched = self.detector.predict(df_clean, threshold=0.5)
        
        if db_insert_normal_only:
            normal_transactions = df_enriched[df_enriched['is_fraud'] == 0]
            suspicious_transactions = df_enriched[df_enriched['is_fraud'] == 1]
            
            logger.info(f"âœ… {len(normal_transactions)} normal transactions â†’ Database")
            logger.info(f"ğŸš¨ {len(suspicious_transactions)} suspicious â†’ Separate analysis")
            
            return {
                'load': normal_transactions,  # To database
                'analyze': suspicious_transactions  # To fraud table
            }
        
        return {'all': df_enriched}
    
    # ============================================================
    # INTEGRATION POINT 3: PARALLEL ANALYSIS (Advanced)
    # ============================================================
    
    def parallel_ai_analysis(self, raw_transactions):
        """
        BEST APPROACH FOR ADVANCED INSIGHTS
        
        Flow (Parallel):
        Extract â†’ Transform â”€â”€â†’ Load to DB
                          â””â”€â”€â†’ AI Fraud Detection (parallel)
                          â””â”€â”€â†’ Pattern Analysis (parallel)
                          â””â”€â”€â†’ Visualization (parallel)
        
        Advantages:
        âœ… Don't wait for AI (non-blocking)
        âœ… Load data immediately
        âœ… AI runs in background
        âœ… Best for production at scale
        """
        logger.info("ğŸ§  PARALLEL AI ANALYSIS (Point 3: Separate Track)")
        
        df_clean = transform_data(raw_transactions)
        
        # These can run in parallel threads/processes
        results = {
            'main_data': df_clean,  # Load to database immediately
            'fraud_scores': self.detector.predict(df_clean),  # Run in parallel
            'anomalies': self.detector.anomaly_detection(df_clean),  # Run in parallel
        }
        
        return results


# ============================================================
# WHICH INTEGRATION POINT TO USE?
# ============================================================

INTEGRATION_GUIDE = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  AI INTEGRATION POINTS - QUICK GUIDE                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                        â•‘
â•‘ ğŸ“ POINT 1: AFTER TRANSFORM (â­ RECOMMENDED FOR REAL-TIME)             â•‘
â•‘    Extract â†’ Transform â†’ AI âœ¨ â†’ Output                              â•‘
â•‘    When to use:                                                       â•‘
â•‘      â€¢ Real-time data processing                                      â•‘
â•‘      â€¢ No database storage needed                                     â•‘
â•‘      â€¢ Streaming fraud alerts                                         â•‘
â•‘      â€¢ Discord/Webhook notifications                                  â•‘
â•‘    Example: realtime_processor.py integration                         â•‘
â•‘                                                                        â•‘
â•‘ ğŸ“ POINT 2: BEFORE LOAD (â­ RECOMMENDED FOR STORAGE)                   â•‘
â•‘    Extract â†’ Transform â†’ AI Filter â†’ Load (safe only)                 â•‘
â•‘    When to use:                                                       â•‘
â•‘      â€¢ Have PostgreSQL setup                                          â•‘
â•‘      â€¢ Want clean database (no fraud data)                            â•‘
â•‘      â€¢ Store normal transactions only                                 â•‘
â•‘      â€¢ Analyze fraud separately                                       â•‘
â•‘    Example: main_etl.py with fraud filter                             â•‘
â•‘                                                                        â•‘
â•‘ ğŸ“ POINT 3: PARALLEL ANALYSIS (â­ RECOMMENDED FOR SCALE)               â•‘
â•‘    Extract â†’ Transform â†’ Load immediately                             â•‘
â•‘                      â””â†’ AI analysis (background threads)              â•‘
â•‘    When to use:                                                       â•‘
â•‘      â€¢ High-volume production system                                  â•‘
â•‘      â€¢ Don't want to slow down loading                                â•‘
â•‘      â€¢ AI runs in background                                          â•‘
â•‘      â€¢ Load all data, analyze later                                   â•‘
â•‘    Example: scheduler.py with threading                               â•‘
â•‘                                                                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

QUICK DECISION TREE:

Do you have storage (PostgreSQL)?
â”œâ”€ NO  â†’ Use POINT 1 (After Transform)
â”‚        Stream + Analyze in real-time
â”‚        No database needed
â”‚
â””â”€ YES â†’ High volume?
         â”œâ”€ NO  â†’ Use POINT 2 (Before Load)
         â”‚        Filter & store only safe transactions
         â”‚
         â””â”€ YES â†’ Use POINT 3 (Parallel)
                   Load immediately, AI runs in background

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

if __name__ == "__main__":
    print(INTEGRATION_GUIDE)
